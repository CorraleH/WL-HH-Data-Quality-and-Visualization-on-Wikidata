{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "55c69ad8-5ff4-43fd-b7a6-8f05cf35fafe",
   "metadata": {
    "id": "55c69ad8-5ff4-43fd-b7a6-8f05cf35fafe"
   },
   "source": [
    "# Laboratório de Qualidade e Visualização de Dados no Wikidata"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a98814ae-eaaa-404d-a5d2-a72d478a70f6",
   "metadata": {
    "id": "a98814ae-eaaa-404d-a5d2-a72d478a70f6",
    "panel-layout": {
     "height": 131.688,
     "visible": true,
     "width": 100
    }
   },
   "source": [
    "Neste tutorial, exploramos ferramentas e técnicas para avaliação da qualidade de dados e visualização no Wikidata, utilizando Python no PAWS Notebook.\n",
    "\n",
    "Vamos abordar quatro ferramentas principais: ProVe, ORES/LiftWing, Recoin e consultas SPARQL (incluindo a recente divisão do grafo WDQS Graph Split). Para cada tópico, explicamos o contexto no Wikidata e demonstramos com exemplos em Python, utilizando a biblioteca Pywikibot e APIs da Wikimedia quando apropriado"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "759f7456-9781-45ff-ac8f-afac4655f374",
   "metadata": {
    "id": "759f7456-9781-45ff-ac8f-afac4655f374",
    "panel-layout": {
     "height": 97.4125,
     "visible": true,
     "width": 100
    }
   },
   "source": [
    "**O que é uma API**\n",
    "\n",
    "Uma API (Interface de Programação de Aplicações) é um conjunto de regras e padrões que permite que diferentes sistemas, softwares ou serviços se comuniquem entre si. Ela funciona como uma ponte, facilitando o envio e recebimento de dados de forma estruturada e segura."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4af8d5e3-dde5-42e2-9c7f-f1079526a39d",
   "metadata": {
    "id": "4af8d5e3-dde5-42e2-9c7f-f1079526a39d",
    "panel-layout": {
     "height": 97.4126,
     "visible": true,
     "width": 100
    }
   },
   "source": [
    "**O que é um Grafo**\n",
    "\n",
    "Um Grafo é uma estrutura de dados que representa relações entre elementos. Ele é formado por nós (ou vértices), que representam entidades, e arestas (ou ligações), que representam as conexões entre esses nós. É amplamente usado em redes sociais, mapas, biologia e bancos de dados relacionais como o Wikidata."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65a7dfee-f0c6-4850-9048-d06418aebf60",
   "metadata": {
    "id": "65a7dfee-f0c6-4850-9048-d06418aebf60",
    "panel-layout": {
     "height": 76.525,
     "visible": true,
     "width": 100
    }
   },
   "source": [
    "## ProVe: Automated PROvenance VErification of Knowledge Graphs against Textual Sources"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0129ee2e-7248-4010-a16b-0fc32546bb1f",
   "metadata": {
    "id": "0129ee2e-7248-4010-a16b-0fc32546bb1f",
    "panel-layout": {
     "height": 51.1376,
     "visible": true,
     "width": 100
    }
   },
   "source": [
    "**Verificabilidade:** existência de fontes confiáveis que sustentem as afirmações."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a94f076a-a1d2-4919-ac85-2d304dee1950",
   "metadata": {
    "id": "a94f076a-a1d2-4919-ac85-2d304dee1950",
    "panel-layout": {
     "height": 10,
     "visible": true,
     "width": 100
    }
   },
   "source": [
    "ProVe é uma ferramenta que verifica automaticamente as referências das afirmações (declaração) em itens do Wikidata usando inteligência artificial. Baseado em modelos de linguagem e aprendizado de máquina, o ProVe analisa cada instância e suas fontes para checar se a referência realmente suporta aquela informação, atribuindo uma pontuação de qualidade indicativa para cada afirmação. Em outras palavras, ele ajuda a validar se os dados inseridos em um item estão corretamente referenciados. Essa ferramenta é disponibilizada como uma ferramenta no próprio Wikidata (pode ser ativada como uma ferramenta de usuário) e auxilia os editores a identificar possíveis problemas de referências em itens específicos.\n",
    "\n",
    "No contexto de qualidade de dados, referências confiáveis são fundamentais. O ProVe facilita a visualização da confiabilidade de cada declaração: se uma afirmação possui referências consideradas inadequadas ou conflitantes, o ProVe pode sinalizar isso com uma pontuação menor, enquanto declarações bem referenciadas recebem pontuação maior, indicando maior confiança. Embora o ProVe opere principalmente através da interface web do Wikidata, podemos programaticamente inspecionar as referências de um item usando a API do Wikidata. A seguir, vamos demonstrar como obter via Python uma lista de afirmações de um item e verificar quantas referências cada uma possui (o que nos dá uma ideia geral da cobertura de referências desse item).\n",
    "\n",
    "[https://www.wikidata.org/wiki/Wikidata:ProVe]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c407c0b4-97ff-4072-a428-69dfd24a4547",
   "metadata": {
    "id": "c407c0b4-97ff-4072-a428-69dfd24a4547",
    "outputId": "66e073a8-804f-4cae-96dc-e6cd41d67f85"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Solicitando processamento do item Q12133...\n",
      "Status: {'algo_version': '1.1.1', 'qid': 'Q12133', 'status': 'completed', 'task_id': '5aeddf3a-d9e0-4d2e-81ff-bc628fa27d6f'}\n",
      "\n",
      "=== Resultado Simplificado ===\n",
     }
   ],
   "source": [
    "import time\n",
    "import requests\n",
    "\n",
    "BASE_URL = \"https://kclwqt.sites.er.kcl.ac.uk/api\"\n",
    "QID = \"Q12133\"  # identificador do Wikidata\n",
    "\n",
    "def request_item(qid):\n",
    "    url = f\"{BASE_URL}/requests/requestItem\"\n",
    "    params = {\"qid\": qid}\n",
    "    r = requests.get(url, params=params)\n",
    "    r.raise_for_status()\n",
    "    return r.json()\n",
    "\n",
    "def check_status(qid):\n",
    "    url = f\"{BASE_URL}/items/checkItemStatus\"\n",
    "    params = {\"qid\": qid}\n",
    "    r = requests.get(url, params=params)\n",
    "    r.raise_for_status()\n",
    "    return r.json()\n",
    "\n",
    "def get_simple_result(qid):\n",
    "    url = f\"{BASE_URL}/items/getSimpleResult\"\n",
    "    params = {\"qid\": qid}\n",
    "    r = requests.get(url, params=params)\n",
    "    r.raise_for_status()\n",
    "    return r.json()\n",
    "\n",
    "def main():\n",
    "    print(f\"Solicitando processamento do item {QID}...\")\n",
    "    request_item(QID)\n",
    "\n",
    "    # Aguarda até que o processamento seja concluído\n",
    "    while True:\n",
    "        status = check_status(QID)\n",
    "        print(\"Status:\", status)\n",
    "        if status.get(\"status\") == \"completed\":\n",
    "            break\n",
    "        elif status.get(\"status\") == \"error\":\n",
    "            print(\"Erro no processamento:\", status)\n",
    "            return\n",
    "        time.sleep(5)  # espera 5s antes de checar de novo\n",
    "\n",
    "    # Recupera resultado simples\n",
    "    result = get_simple_result(QID)\n",
    "    print(\"\\n=== Resultado Simplificado ===\")\n",
    "    print(result)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46200a23-8f9f-49ee-8fc2-e2bfa1bc485c",
   "metadata": {
    "id": "46200a23-8f9f-49ee-8fc2-e2bfa1bc485c",
    "panel-layout": {
     "height": 80.275,
     "visible": true,
     "width": 100
    }
   },
   "source": [
    "Documentação da API em [https://kclwqt.sites.er.kcl.ac.uk/apidocs/]\n",
    "\n",
    "**getSimpleResult:** [https://kclwqt.sites.er.kcl.ac.uk/api/items/getSimpleResult?qid=Q44]\n",
    "\n",
    "**getCompResult:** [https://kclwqt.sites.er.kcl.ac.uk/api/items/getCompResult?qid=Q12133]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e84f76df-fc3c-4023-9004-0d72813582d5",
   "metadata": {
    "id": "e84f76df-fc3c-4023-9004-0d72813582d5",
    "panel-layout": {
     "height": 50.8125,
     "visible": true,
     "width": 100
    }
   },
   "source": [
    "## Pywikibot: Inspecionando referências no Wikidata"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e28ad215-962e-42a9-a380-b5c90aa3d000",
   "metadata": {
    "id": "e28ad215-962e-42a9-a380-b5c90aa3d000",
    "panel-layout": {
     "height": 148.825,
     "visible": true,
     "width": 100
    }
   },
   "source": [
    "No exemplo abaixo, usamos a biblioteca Pywikibot para acessar o item Douglas Adams (Q42) no Wikidata e listar algumas propriedades com a contagem de referências em cada declaração. O Pywikibot facilita o acesso via API, abstracionando detalhes da MediaWiki API. Primeiro conectamos ao repositório do Wikidata e carregamos o item Q42. Em seguida, iteramos sobre suas declarações (claims) para contar as referências de cada uma. Isso não é exatamente o que o ProVe faz (que é verificar o conteúdo das referências), mas serve para ilustrar a exploração de referências de forma programática:\n",
    "\n",
    "\n",
    "Douglas Adams([https://www.wikidata.org/wiki/Q42])\n",
    "\n",
    "Audiologia computacional([https://www.wikidata.org/wiki/Q110852808])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c22d68f-a17c-4389-aace-996eefcedb9f",
   "metadata": {
    "id": "4c22d68f-a17c-4389-aace-996eefcedb9f",
    "outputId": "ceb7f08b-0c77-43ee-f296-36f215f9bb72"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "P31: 3 referência(s)\n",
      "P21: 3 referência(s)\n",
      "P106: 0 referência(s)\n",
      "P800: 1 referência(s)\n",
      "P569: 15 referência(s)\n"
     ]
    }
   ],
   "source": [
    "import pywikibot\n",
    "\n",
    "# Configura a conexão com o Wikidata\n",
    "site = pywikibot.Site(\"wikidata\", \"wikidata\")\n",
    "repo = site.data_repository()\n",
    "\n",
    "# Carrega o item Douglas Adams (Q42)\n",
    "item = pywikibot.ItemPage(repo, \"Q42\")\n",
    "item.get()  # Obtém os dados do item via API\n",
    "\n",
    "# Itera pelas primeiras 5 propriedades para demonstrar\n",
    "claims = item.claims\n",
    "for prop_id, claim_list in list(claims.items())[:5]:\n",
    "    num_refs = 0\n",
    "    # Conta referências da primeira declaração dessa propriedade\n",
    "    if claim_list:\n",
    "        num_refs = len(claim_list[0].sources)\n",
    "    print(f\"{prop_id}: {num_refs} referência(s)\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "781215d9-edf9-40dc-b8e3-45056995b781",
   "metadata": {
    "id": "781215d9-edf9-40dc-b8e3-45056995b781",
    "panel-layout": {
     "height": 85.4125,
     "visible": true,
     "width": 100
    }
   },
   "source": [
    "Cada linha mostra o identificador da propriedade e quantas referências estão anexadas a ela na primeira declaração. No caso do item Q42, vemos por exemplo que a propriedade P31 (instância de) tem 3 referências suportando a afirmação \"Douglas Adams é instância de humano\" (o que é desejável), enquanto outras propriedades podem não ter referências (ex.: P21 gênero, P106 ocupação, etc.). Essa inspeção manual dá uma noção da completude de fontes em um item. O ProVe, por sua vez, vai além: ele lê o conteúdo das referências e verifica automaticamente se elas corroboram as informações da declaração, fornecendo um indicador de qualidade de referência para cada afirmação"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be8910b5-c683-4b0a-889a-d8449cef0c20",
   "metadata": {
    "id": "be8910b5-c683-4b0a-889a-d8449cef0c20",
    "outputId": "d9be7685-e466-4ad5-95d6-18c78b3e5588"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "P31: 1 referência(s)\n",
      "P1448: 2 referência(s)\n",
      "P361: 2 referência(s)\n",
      "P3095: 0 referência(s)\n",
      "P279: 0 referência(s)\n"
     ]
    }
   ],
   "source": [
    "import pywikibot\n",
    "\n",
    "# Configura a conexão com o Wikidata\n",
    "site = pywikibot.Site(\"wikidata\", \"wikidata\")\n",
    "repo = site.data_repository()\n",
    "\n",
    "# Carrega o item audiologia computacional (Q110852808)\n",
    "item = pywikibot.ItemPage(repo, \"Q110852808\")\n",
    "item.get()  # Obtém os dados do item via API\n",
    "\n",
    "# Itera pelas primeiras 5 propriedades para demonstrar\n",
    "claims = item.claims\n",
    "for prop_id, claim_list in list(claims.items())[:5]:\n",
    "    num_refs = 0\n",
    "    # Conta referências da primeira declaração dessa propriedade\n",
    "    if claim_list:\n",
    "        num_refs = len(claim_list[0].sources)\n",
    "    print(f\"{prop_id}: {num_refs} referência(s)\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b44a2fe8-41b0-4273-827a-b931ed0487d3",
   "metadata": {
    "id": "b44a2fe8-41b0-4273-827a-b931ed0487d3",
    "panel-layout": {
     "height": 50.8125,
     "visible": true,
     "width": 100
    }
   },
   "source": [
    "## ORES-LiftWing: Avaliação Automática de Qualidade"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d090a0cd-247a-43cd-88b9-887586d95a41",
   "metadata": {
    "id": "d090a0cd-247a-43cd-88b9-887586d95a41",
    "panel-layout": {
     "height": 51.1375,
     "visible": true,
     "width": 100
    }
   },
   "source": [
    "**Completude:** presença de todas as informações relevantes esperadas em um item ou conjunto de dados.\n",
    "**Estrutura**: combinação de vários aspectos (número de declarações, referências, rótulos, sitelinks) que refletem o quão completo e estruturado está um item"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2aab515-698a-48c8-b30d-9f7db80feb4e",
   "metadata": {
    "id": "b2aab515-698a-48c8-b30d-9f7db80feb4e",
    "panel-layout": {
     "height": 258.513,
     "visible": true,
     "width": 100
    }
   },
   "source": [
    "ORES (Objective Revision Evaluation Service) é um serviço de aprendizado de máquina da Wikimedia que fornece pontuações automáticas para edições e itens, com foco em detectar vandalismo e avaliar a qualidade do conteúdo. No contexto do Wikidata, o ORES foi treinado para tarefas como:\n",
    "\n",
    "1. Detecção de vandalismo em edições: O ORES atribui a cada edição uma probabilidade de ser danosa (vandalismo) ou de boa-fé. Por exemplo, é possível obter via API a probabilidade de uma determinada edição ser vandalismo auxiliando filtros de mudanças recentes a destacar edições potencialmente problemáticas.\n",
    "2. Classificação da qualidade de itens: O ORES também mantém um modelo que estima a qualidade dos itens do Wikidata, classificando-os em níveis de A a E (sendo \"A\" itens mais completos e de alta qualidade, e \"E\" itens muito incompletos). Esse modelo considera aspectos estruturais do item (número de declarações, presença de referências, uso de qualificadores, etc.) para predizer um nível de qualidade semelhante às avaliações feitas manualmente pela comunidade.\n",
    "\n",
    "Atualmente, a infraestrutura do ORES está sendo substituída pelo LiftWing, sendo a nova plataforma de serviço dos modelos de aprendizagem de máquina na Wikimedia. O LiftWing hospeda os mesmos modelos de previsão do ORES, porém em uma arquitetura mais moderna e escalável. Em termos práticos para os usuários e desenvolvedores, as funcionalidades permanecem as mesmas: podemos fazer requisições para obter pontuações de qualidade ou vandalismo, somente mudando (no futuro) a URL/endpoint da API. No momento (2025), o endpoint do ORES continua ativo e podemos utilizá-lo para demonstração.\n",
    "\n",
    "Para ilustrar, vamos usar o modelo de qualidade de item do Wikidata. Esse modelo analisa o item em uma determinada revisão e retorna a probabilidade de o item pertencer a cada classe de qualidade (A, B, C, D ou E), além de indicar a classe prevista com maior probabilidade. Vamos consultar a API do ORES para o item Q42 (Douglas Adams) em sua revisão mais recente e ver qual classe de qualidade o modelo atribui a esse item. Utilizaremos Python para obter o ID da revisão atual do item e então chamar a API do ORES."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a834c72a-7b36-45f5-8343-2b06c0eb7e55",
   "metadata": {
    "id": "a834c72a-7b36-45f5-8343-2b06c0eb7e55",
    "panel-layout": {
     "height": 97.4125,
     "visible": true,
     "width": 100
    }
   },
   "source": [
    "**Exemplo 1:** Obtendo a qualidade estimada do item Q42\n",
    "\n",
    "No código abaixo, novamente usamos Pywikibot para obter o item Q42 e extrair seu ID de revisão atual. Em seguida, montamos a URL da API do ORES para o modelo itemquality do Wikidata, passando o ID de revisão obtido. Fazemos a requisição e interpretamos o JSON de resposta para imprimir a classe de qualidade prevista e as probabilidades associadas a cada nível:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "304540ff-a4a6-4bea-a410-5c11fde5dde8",
   "metadata": {
    "id": "304540ff-a4a6-4bea-a410-5c11fde5dde8",
    "outputId": "db94b99a-ce16-4d27-dfc0-4941950aecd0"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Revisão atual de Q42: 2387251667\n",
      "Classe de qualidade prevista: A\n",
      "Probabilidade de A: 0.96\n",
      "Probabilidade de B: 0.02\n",
      "Probabilidade de C: 0.02\n",
      "Probabilidade de D: 0.00\n",
      "Probabilidade de E: 0.00\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "import pywikibot\n",
    "\n",
    "# Configura a conexão com o Wikidata\n",
    "site = pywikibot.Site(\"wikidata\", \"wikidata\")\n",
    "repo = site.data_repository()\n",
    "\n",
    "# Carrega o item Douglas Adams (Q42)\n",
    "item = pywikibot.ItemPage(repo, \"Q42\")\n",
    "item.get()  # Obtém os dados do item via API\n",
    "\n",
    "# Obter o ID da última revisão do item Q42\n",
    "rev_id = item.latest_revision_id\n",
    "print(\"Revisão atual de Q42:\", rev_id)\n",
    "\n",
    "# Monta a URL da API do ORES para o modelo de qualidade de item (itemquality)\n",
    "ores_url = f\"https://ores.wikimedia.org/v3/scores/wikidatawiki/?models=itemquality&revids={rev_id}\"\n",
    "response = requests.get(ores_url)\n",
    "data = response.json()\n",
    "\n",
    "# Extrai a pontuação do modelo itemquality para a revisão dada\n",
    "score = data[\"wikidatawiki\"][\"scores\"][str(rev_id)][\"itemquality\"][\"score\"]\n",
    "pred_class = score[\"prediction\"]\n",
    "probs = score[\"probability\"]\n",
    "\n",
    "print(f\"Classe de qualidade prevista: {pred_class}\")\n",
    "for cls, prob in probs.items():\n",
    "    print(f\"Probabilidade de {cls}: {prob:.2f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2cf327eb-ec81-463e-aae6-d1e5fc929b35",
   "metadata": {
    "id": "2cf327eb-ec81-463e-aae6-d1e5fc929b35",
    "panel-layout": {
     "height": 51.1375,
     "visible": true,
     "width": 100
    }
   },
   "source": [
    "*No código acima, usamos a estrutura do retorno JSON do ORES: a resposta traz, para cada revid, as probabilidades de cada classe e a classe prediction com maior probabilidade. Iteramos por probs para exibir cada classe A-E com sua probabilidade.*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f587fd69-2d1e-4174-b830-4741ed9a2fc1",
   "metadata": {
    "id": "f587fd69-2d1e-4174-b830-4741ed9a2fc1",
    "panel-layout": {
     "height": 131.688,
     "visible": true,
     "width": 100
    }
   },
   "source": [
    "Isso indica que, de acordo com o modelo ORES, o item Q42 está classificado como classe A, com 95% de confiança aproximadamente. Classe A no esquema de qualidade do Wikidata corresponde a um item altamente completo: contém todas as informações relevantes com referências sólidas, rótulos/descrições em várias línguas, aliases, sitelinks, etc. Essa previsão faz sentido, pois Douglas Adams (Q42) é um item bastante preenchido e serve até como exemplo de item de qualidade máxima.\n",
    "\n",
    "Vale notar que o ORES é utilizado dentro do Wikidata para melhorar a moderação e priorização: as pontuações de edições (vandalismo ou “damaging”) estão integradas nos filtros de mudanças recentes e páginas vigiadas, e as pontuações de item quality podem ser usadas por pesquisadores ou ferramentas para acompanhar a evolução da qualidade dos itens ou sugerir focos de melhoria. Com a migração para o LiftWing, essas capacidades devem continuar, mas acessadas por meio do novo endpoint de API da infraestrutura de machine learning da Wikimedia."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0loMnK_5nwZq",
   "metadata": {
    "id": "0loMnK_5nwZq"
   },
   "source": [
    "**Exemplo 2:** Obtendo a qualidade estimada do item Q569965 (audiologia)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52a4a4f9-f7c4-41ab-9c89-3313cc292ff5",
   "metadata": {
    "id": "52a4a4f9-f7c4-41ab-9c89-3313cc292ff5",
    "outputId": "0a3380f8-7dc2-4f3a-fb12-c7c55988316f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Revisão atual de Q569965: 2394995421\n",
      "Classe de qualidade prevista: B\n",
      "Probabilidade de A: 0.08\n",
      "Probabilidade de B: 0.82\n",
      "Probabilidade de C: 0.08\n",
      "Probabilidade de D: 0.01\n",
      "Probabilidade de E: 0.00\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "import pywikibot\n",
    "\n",
    "# Configura a conexão com o Wikidata\n",
    "site = pywikibot.Site(\"wikidata\", \"wikidata\")\n",
    "repo = site.data_repository()\n",
    "\n",
    "# Carrega o item audiologia Q569965\n",
    "item = pywikibot.ItemPage(repo, \"Q569965\")\n",
    "item.get()  # Obtém os dados do item via API\n",
    "\n",
    "# Obter o ID da última revisão do item Q569965\n",
    "rev_id = item.latest_revision_id\n",
    "print(\"Revisão atual de Q569965:\", rev_id)\n",
    "\n",
    "# Monta a URL da API do ORES para o modelo de qualidade de item (itemquality)\n",
    "ores_url = f\"https://ores.wikimedia.org/v3/scores/wikidatawiki/?models=itemquality&revids={rev_id}\"\n",
    "response = requests.get(ores_url)\n",
    "data = response.json()\n",
    "\n",
    "# Extrai a pontuação do modelo itemquality para a revisão dada\n",
    "score = data[\"wikidatawiki\"][\"scores\"][str(rev_id)][\"itemquality\"][\"score\"]\n",
    "pred_class = score[\"prediction\"]\n",
    "probs = score[\"probability\"]\n",
    "\n",
    "print(f\"Classe de qualidade prevista: {pred_class}\")\n",
    "for cls, prob in probs.items():\n",
    "    print(f\"Probabilidade de {cls}: {prob:.2f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a899427f-3b8e-45e3-be80-77d00c47cd3f",
   "metadata": {
    "id": "a899427f-3b8e-45e3-be80-77d00c47cd3f",
    "panel-layout": {
     "height": 50.8125,
     "visible": true,
     "width": 100
    }
   },
   "source": [
    "## Recoin: Indicador de Completude Relativa de Itens"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0ab22b6-2cb2-4a2c-90b5-e0e58e07c7ed",
   "metadata": {
    "id": "b0ab22b6-2cb2-4a2c-90b5-e0e58e07c7ed",
    "panel-layout": {
     "height": 51.1375,
     "visible": true,
     "width": 100
    }
   },
   "source": [
    "**Completude**: presença de todas as informações relevantes esperadas em um item ou conjunto de dados."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11a4bc00-9dde-4989-a702-f482e7f37bb6",
   "metadata": {
    "id": "11a4bc00-9dde-4989-a702-f482e7f37bb6",
    "panel-layout": {
     "height": 351.062,
     "visible": true,
     "width": 100
    }
   },
   "source": [
    "Recoin (Relative Completeness Indicator) é uma ferramenta que avalia o quão completo está um item do Wikidata em comparação com itens semelhantes. Ele funciona como um indicador de completude relativa, mostrando ao editor quais informações ainda faltam em um item e que geralmente estão presentes em itens do mesmo tipo. Por exemplo, se estamos editando um item sobre uma pessoa e esse item não possui a propriedade \"nacionalidade\", mas a maioria das pessoas semelhantes têm, o Recoin destacará \"nacionalidade\" como um atributo ausente importante.\n",
    "\n",
    "A ferramenta se integra à interface do Wikidata adicionando um ícone de classificação colorida (no canto superior direito da página do item) e listas expansíveis com as principais propriedades faltantes para aquele item. O ícone de classificação resume a completude do item em cinco níveis (de muito básico a muito detalhado) com uma barra de progresso colorido. Esses níveis são definidos com base na frequência dos atributos ausentes nos itens similares. Em termos simples:\n",
    "\n",
    "___Nível 5 (mais completo):___ as principais propriedades ausentes são muito raras entre os similares (aparecem em somente 0%–5% dos itens comparáveis)\n",
    "\n",
    "___Nível 4 (quase completo):___ os atributos faltantes ocorrem em ~5%–10% dos itens similares\n",
    "\n",
    "___Nível 3 (médio):___ os atributos ausentes estão em 10%–25% dos similares\n",
    "\n",
    "___Nível 2 (baixa completude):___ propriedades ausentes presentes em 25%–50% dos similares\n",
    "\n",
    "___Nível 1 (menos completo):___ as propriedades faltantes são muito comuns (>50%) nos itens similares, indicando que muita informação essencial está ausente.\n",
    "\n",
    "Por exemplo, um item cujo indicador estava no nível 2 (baixo), pois ele não tinha várias propriedades que mais de 40%–50% dos itens nas mesma categoria/tipo possuem. A média de frequência dos top 5 atributos faltantes dele era ~42.5%, enquadrando-o no nível 2 de completude. Com essa informação, um editor saberia exatamente quais propriedades adicionar para melhorar a completude daquele item."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "D36bfXbJoGFT",
   "metadata": {
    "id": "D36bfXbJoGFT"
   },
   "source": [
    "O Recoin beneficia tanto consumidores quanto editores dos dados:\n",
    "1. Para usuários que consomem os dados, o indicador dá uma noção rápida se um item está muito completo ou não, o que pode influenciar a confiabilidade de usar aquele item para obter informação.\n",
    "2. Para editores, o Recoin aponta onde focar esforços de edição, sugerindo os atributos importantes que faltam em um item para torná-lo tão completo quanto seus pares. Ele ajuda a priorizar melhorias em itens menos completos.\n",
    "\n",
    "Além da interface interativa, o Recoin disponibiliza também uma API pública (hospedada em Toolforge) para acesso programático aos cálculos de completude.\n",
    "\n",
    "Essa API não requer autenticação e pode ser usada por qualquer pessoa para avaliar itens em larga escala ou incorporar o indicador em outras ferramentas. A API retorna, para um item dado, o nível de completude e a lista dos principais atributos ausentes (podendo retornar tanto os nomes quanto os IDs das propriedades).\n",
    "\n",
    "A seguir, vamos usar a API do Recoin para obter os atributos faltantes do item de exemplo Douglas Adams (Q42), já que ele foi citado como exemplo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "7H-_IevLoUVB",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "7H-_IevLoUVB",
    "outputId": "e69e5249-258f-449a-a5c7-c09d49bd5ab9"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Atributos ausentes sugeridos para Q569965:\n",
      "- P2521: presente em 42.31% de itens semelhantes\n",
      "- P425: presente em 35.90% de itens semelhantes\n",
      "- P3321: presente em 10.47% de itens semelhantes\n",
      "- P18: presente em 9.02% de itens semelhantes\n",
      "- P17: presente em 3.40% de itens semelhantes\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "\n",
    "# URL da API do Recoin para obter atributos faltantes (5 principais) do item Q569965 (audiologia)\n",
    "item_id = \"Q569965\"\n",
    "url = f\"https://tools.wmflabs.org/recoin/getmissingattributes.php?lang=pt&subject={item_id}&n=5\"\n",
    "res = requests.get(url)\n",
    "data = res.json()\n",
    "\n",
    "print(f\"Atributos ausentes sugeridos para {item_id}:\")\n",
    "for attr in data[\"missing_properties\"]:\n",
    "    prop_label = attr[\"property\"]        # identificador propriedade\n",
    "    frequency = float(attr[\"base_frequency\"].strip('%'))  # frequência percentual nos itens similares\n",
    "    print(f\"- {prop_label}: presente em {frequency:.2f}% de itens semelhantes\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "qSF16Fh9ouWF",
   "metadata": {
    "id": "qSF16Fh9ouWF"
   },
   "source": [
    "No código acima utilizamos o módulo requests para fazer uma requisição HTTP à API do Recoin. Usamos o endpoint getmissingattributes.php, passando os parâmetros de idioma (lang) e o item (subject) por Q-ID, além de n=5 para limitar a 5 propriedades sugeridas. Em seguida, interpretamos o JSON retornado e exibimos as propriedades ausentes e seus percentuais de frequência nos itens similares (que indicam a importância de cada atributo faltante):"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "loxL77jzzH28",
   "metadata": {
    "id": "loxL77jzzH28"
   },
   "source": [
    "Atributos ausentes sugeridos para Q569965 (Q569965):\n",
    "\n",
    "*   P2521 (forma feminina do rótulo): presente em 42.31% de itens semelhantes\n",
    "\n",
    "*   P425 (campo dessa ocupação): presente em 35.90% de itens semelhantes\n",
    "\n",
    "*   P3321 (forma masculina do rótulo): presente em 10.47% de itens semelhantes\n",
    "\n",
    "*   P18 (imagem): presente em 9.02% de itens semelhantes\n",
    "\n",
    "*   P17 (país): presente em 3.40% de itens semelhantes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "QdBnMzVg0BR5",
   "metadata": {
    "id": "QdBnMzVg0BR5"
   },
   "source": [
    "## SPARQL e Wikidata Query Service (WDQS) – Consultas e WDQS Graph Split"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "IMEWog8F0E7c",
   "metadata": {
    "id": "IMEWog8F0E7c"
   },
   "source": [
    "SPARQL refere-se a \"SPARQL Protocol and RDF Query Language\", uma linguagem de consultas destinada a dados em formato RDF (Resource Description Framework). O Wikidata Query Service (WDQS) é o serviço público que disponibiliza um endpoint SPARQL para consultar os dados do Wikidata. Em outras palavras, o WDQS permite que usuários escrevam consultas SPARQL para recuperar informações arbitrariamente complexas do banco de dados do Wikidata.\n",
    "\n",
    "Diferentemente das consultas simples via API (que geralmente recuperam dados de um item específico), o SPARQL possibilita varrer o grafo completo do Wikidata com consultas declarativas. Você pode, por exemplo, pedir: \"Liste todos os países e suas capitais\", \"Encontre pinturas de artistas nascidos no século XIX\", \"Conte quantas entidades do tipo doença possuem uma certa propriedade preenchida\", e assim por diante. O poder do SPARQL está em usar padrões de triplas (sujeito – predicado – objeto) para fazer inferências a partir dos relacionamentos entre itens.\n",
    "\n",
    "No contexto do Wikidata, cada declaração pode ser vista como uma tripla RDF. Por exemplo, a afirmação \"Brasil – capital – Brasília\" corresponde a uma tripla em que o sujeito é o item Brasil (Q155), o predicado é a propriedade capital (P36) e o objeto é o item Brasília (Q2844). Em SPARQL, usando prefixos abreviados, escreveríamos algo como:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "lB6QrmHa0UCw",
   "metadata": {
    "id": "lB6QrmHa0UCw"
   },
   "source": [
    "**wd:Q155 wdt:P36 wd:Q2844 .**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "kZT3nZ4D0WaQ",
   "metadata": {
    "id": "kZT3nZ4D0WaQ"
   },
   "source": [
    "Esse comando consulta se existe essa relação no grafo. Podemos combinar múltiplos padrões para extrair informações ligadas.\n",
    "\n",
    "O WDQS oferece extensões úteis, como a palavra-chave SERVICE wikibase:label para obter rótulos humanos dos Q-ids automaticamente no idioma desejado, facilitando a legibilidade dos resultados.\n",
    "\n",
    "Executando consultas SPARQL: O WDQS disponibiliza uma interface web (em https://query.wikidata.org) onde podemos escrever e testar consultas com saída em vários formatos (tabela, gráfico, mapa, etc.). Também podemos acessar o serviço programaticamente via HTTP – basta enviar nossa query para o endpoint e especificar o formato de retorno (JSON, CSV, etc.). A seguir, faremos uma demonstração de uma consulta SPARQL simples usando Python, consultando o endpoint do WDQS diretamente.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "gbwt12_10wh-",
   "metadata": {
    "id": "gbwt12_10wh-"
   },
   "source": [
    "Mas antes, é importante comentar uma atualização recente: o WDQS Graph Split. Em maio de 2025, devido ao enorme volume de dados do Wikidata (mais de 16 bilhões de triplas e crescendo), o grafo do Wikidata foi dividido em dois subgrafos para melhorar a escalabilidade. Agora existem:\n",
    "*    O grafo principal: contendo a maioria dos itens do Wikidata (todos exceto os acadêmicos).\n",
    "*    O grafo de publicações acadêmicas: contendo itens que são instâncias de artigo científico (Q13442814) ou outros tipos acadêmicos definidos nas regras de divisão. Correspondentemente, temos dois endpoints SPARQL:\n",
    "\n",
    "*    **query.wikidata.org/sparql para o grafo principal**\n",
    "\n",
    "*    **query-scholarly.wikidata.org/sparql para o grafo acadêmico**\n",
    "\n",
    "Essa separação significa que consultas que envolvem apenas dados gerais (não artigos científicos) continuam funcionando normalmente no endpoint principal, e consultas somente sobre artigos científicos podem ser feitas no endpoint acadêmico. Entretanto, consultas que misturam dados dos dois grafos precisam usar federação SPARQL, fazendo subconsultas em cada endpoint e combinando os resultados.\n",
    "\n",
    "Alternativamente, até o final de 2025, um endpoint legado com o grafo completo está disponível (query-legacy-full.wikidata.org), mas com uso limitado. Para a maioria dos usos, é recomendável ajustar as consultas para a nova estrutura.\n",
    " Por exemplo, se alguém estiver consultando itens do Wikidata sobre publicações científicas e autores (que antes estavam juntos), agora deve dividir a consulta: parte roda no endpoint acadêmico (para dados dos artigos) e, se necessário, usa SERVICE federado para buscar dados complementares no endpoint principal (por exemplo, informações dos autores, que são itens do grafo principal).\n",
    "\n",
    "Para nosso exemplo aqui, usaremos apenas o endpoint principal, garantindo que a consulta envolva somente dados do grafo principal. Vamos escrever uma consulta SPARQL que obtenha uma lista de alguns países e suas capitais, retornando os nomes em português (quando disponíveis). Em seguida, vamos executar essa consulta via Python e exibir os resultados obtidos."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "Gxzxo-1r1NOG",
   "metadata": {
    "id": "Gxzxo-1r1NOG"
   },
   "source": [
    "```\n",
    "SELECT ?country ?countryLabel ?capitalLabel\n",
    "WHERE {\n",
    "  ?country wdt:P31 wd:Q6256;       # ?country é instância de país soberano (Q6256)\n",
    "           wdt:P36 ?capital.       # ?country tem capital ?capital\n",
    "  SERVICE wikibase:label { bd:serviceParam wikibase:language \"pt,en\" }\n",
    "}\n",
    "LIMIT 5\n",
    "\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "YjJZIjLs1a2D",
   "metadata": {
    "id": "YjJZIjLs1a2D"
   },
   "source": [
    "Essa query procura por entidades que sejam instâncias de país (wdt:P31 wd:Q6256) e extrai o valor da sua capital (wdt:P36 ?capital). O SERVICE wikibase:label é usado para trazer os rótulos (?countryLabel e ?capitalLabel) em português, com fallback para inglês caso o rótulo em pt não exista. Limitamos a 5 resultados apenas para demonstração.\n",
    "\n",
    "Agora, vamos executar essa consulta usando uma requisição HTTP GET para o endpoint do WDQS, pedindo o resultado em formato JSON:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "w0QcffdU1Zrg",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "w0QcffdU1Zrg",
    "outputId": "6d0968fe-a0ba-4704-bfe8-5e6c31a2c760"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Irão – capital: Teerão\n",
      "Iraque – capital: Bagdá\n",
      "Costa Rica – capital: San José\n",
      "Israel – capital: Jerusalém\n",
      "Iémen – capital: Sana\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "\n",
    "# Define a consulta SPARQL\n",
    "sparql_query = \"\"\"\n",
    "SELECT ?country ?countryLabel ?capitalLabel WHERE {\n",
    "  ?country wdt:P31 wd:Q6256;\n",
    "           wdt:P36 ?capital.\n",
    "  SERVICE wikibase:label { bd:serviceParam wikibase:language \"pt,en\" }\n",
    "}\n",
    "LIMIT 5\n",
    "\"\"\"\n",
    "\n",
    "# Endpoint do WDQS\n",
    "url = \"https://query.wikidata.org/sparql\"\n",
    "\n",
    "# Faz a requisição\n",
    "res = requests.get(url, params={\"query\": sparql_query, \"format\": \"json\"})\n",
    "data = res.json()\n",
    "\n",
    "# Processa e exibe os resultados\n",
    "for result in data[\"results\"][\"bindings\"]:\n",
    "    country = result[\"countryLabel\"][\"value\"]\n",
    "    capital = result[\"capitalLabel\"][\"value\"]\n",
    "    print(f\"{country} – capital: {capital}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "vwPsL-uB1t7J",
   "metadata": {
    "id": "vwPsL-uB1t7J"
   },
   "source": [
    "*No código acima, montamos a query como string multilinha. Usamos requests.get no endpoint, passando a query e pedindo format=json. O resultado JSON tem uma estrutura onde results[\"bindings\"] é uma lista de resultados, cada um contendo os campos selecionados. Iteramos e extraímos os valores dos rótulos.*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dwNspKSR1_Y5",
   "metadata": {
    "id": "dwNspKSR1_Y5"
   },
   "source": [
    "Essa consulta demonstra a integração de dados estruturados do Wikidata via SPARQL. Em poucas linhas, recuperamos várias peças de informação conectadas (itens país -> item capital -> rótulos). Com consultas SPARQL podemos, por exemplo, gerar listas para verificar consistência de dados ou alimentar visualizações. Há também a possibilidade de visualização de resultados diretamente na interface do Query Service – por exemplo, podemos modificar a consulta para retornar coordenadas geográficas e visualizar um mapa, ou retornar uma lista de elementos e usar o modo Graph para ver uma rede de conexões. Ferramentas como o Scholia (mencionada no contexto do WikiLab) utilizam SPARQL internamente para gerar visualizações acadêmicas (redes de coautoria, gráficos de tópicos, etc.), mostrando o potencial do SPARQL em termos de exploração visual do conhecimento.\n",
    ".\n",
    "\n",
    "Por fim, é importante lembrar das implicações do WDQS Graph Split ao escrever consultas: se quisermos, por exemplo, listar artigos científicos sobre saúde auditiva e seus autores (itens de artigo e itens de pesquisadores), teríamos que combinar resultados dos dois endpoints. Nesse caso, usaríamos a cláusula SERVICE no SPARQL para fazer uma subconsulta federada. Esse é um tópico mais avançado, mas a documentação do Wikidata traz exemplos de consultas federadas após o graph split para orientar os usuários. Para consultas comuns que não envolvem o domínio acadêmico, o endpoint principal continua sendo a ferramenta de escolha."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "qTBYI-RN1pm9",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "qTBYI-RN1pm9",
    "outputId": "73d3ec59-c646-4074-cb31-f09a665e6465"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Resultados da consulta:\n",
      "\n",
      "Pressão de língua em crianças e adolescentes com osteogênese imperfeita (http://www.wikidata.org/entity/Q135915586)\n",
      "Transtorno do zumbido: implicação em diferentes habilidades cognitivas de adultos jovens (http://www.wikidata.org/entity/Q135915626)\n",
      "Análise da variabilidade da frequência cardíaca para identificar a perda auditiva no primeiro ano de vida (http://www.wikidata.org/entity/Q135915638)\n",
      "O que cantores amadores que se apresentam em cultos religiosos conhecem sobre saúde e higiene vocal? (http://www.wikidata.org/entity/Q135915637)\n",
      "Desenvolvimento de habilidades auditivas de crianças no primeiro ano após o implante coclear unilateral e bilateral (http://www.wikidata.org/entity/Q135915642)\n",
      "Atuação fonoaudiológica em pacientes traqueostomizados no contexto da COVID-19 (http://www.wikidata.org/entity/Q135915644)\n",
      "Frequência de queixas de deglutição e alimentação durante consulta compartilhada em cuidados paliativos oncológicos (http://www.wikidata.org/entity/Q135915647)\n",
      "Evidência de validade baseada nos processos de resposta de um protocolo de análise espectrográfica da voz (http://www.wikidata.org/entity/Q135915654)\n",
      "Uso da posturografia para identificação do risco de queda em idosos com tontura (http://www.wikidata.org/entity/Q135915652)\n",
      "Como os fonoaudiólogos realizam avaliação da produção de fala por meio da telessaúde? (http://www.wikidata.org/entity/Q135915659)\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "\n",
    "# Define a consulta SPARQL\n",
    "sparql_query = \"\"\"\n",
    "SELECT DISTINCT ?item ?itemLabel WHERE {\n",
    "  SERVICE wikibase:label { bd:serviceParam wikibase:language \"[AUTO_LANGUAGE],mul,en\". }\n",
    "  {\n",
    "    SELECT DISTINCT ?item WHERE {\n",
    "      ?item p:P1433 ?statement0.\n",
    "      ?statement0 (ps:P1433/(wdt:P279*)) wd:Q50816812.\n",
    "    }\n",
    "  }\n",
    "}\n",
    "LIMIT 10\n",
    "\"\"\"\n",
    "\n",
    "# Endpoint acadêmico (graph split)\n",
    "url = \"https://query-scholarly.wikidata.org/sparql\"\n",
    "res = requests.get(url, params={\"query\": sparql_query, \"format\": \"json\"})\n",
    "data = res.json()\n",
    "\n",
    "# Processa e exibe os resultados\n",
    "print(\"Resultados da consulta:\\n\")\n",
    "for result in data[\"results\"][\"bindings\"]:\n",
    "    item = result[\"item\"][\"value\"]\n",
    "    label = result[\"itemLabel\"][\"value\"]\n",
    "    print(f\"{label} ({item})\")"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  },
  "panel-cell-order": [
   "a94f076a-a1d2-4919-ac85-2d304dee1950",
   "a98814ae-eaaa-404d-a5d2-a72d478a70f6",
   "e28ad215-962e-42a9-a380-b5c90aa3d000",
   "ab63602e-ff33-4450-b356-5753d7698f68",
   "65a7dfee-f0c6-4850-9048-d06418aebf60",
   "759f7456-9781-45ff-ac8f-afac4655f374",
   "4af8d5e3-dde5-42e2-9c7f-f1079526a39d",
   "0129ee2e-7248-4010-a16b-0fc32546bb1f",
   "46200a23-8f9f-49ee-8fc2-e2bfa1bc485c",
   "e84f76df-fc3c-4023-9004-0d72813582d5",
   "781215d9-edf9-40dc-b8e3-45056995b781",
   "b44a2fe8-41b0-4273-827a-b931ed0487d3",
   "d090a0cd-247a-43cd-88b9-887586d95a41",
   "b2aab515-698a-48c8-b30d-9f7db80feb4e",
   "a834c72a-7b36-45f5-8343-2b06c0eb7e55",
   "2cf327eb-ec81-463e-aae6-d1e5fc929b35",
   "f587fd69-2d1e-4174-b830-4741ed9a2fc1",
   "a899427f-3b8e-45e3-be80-77d00c47cd3f",
   "b0ab22b6-2cb2-4a2c-90b5-e0e58e07c7ed",
   "11a4bc00-9dde-4989-a702-f482e7f37bb6"
  ]
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
